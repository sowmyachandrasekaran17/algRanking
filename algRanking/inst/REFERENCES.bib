@book{Bart06a,
Abstract = {Rigorously proven upper and lower run-time bounds for simplified evolutionary algorithms on artificial optimization problems on the one hand and endless tables of benchmark results for real-world algorithms on today's or yesterday's hardware on the other, is that all one can do to justify their invention, existence, or even spreading use? Thomas Bartz-Beielstein gives thoughtful answers to such questions that have bothered him since he joined the team of researchers at the Chair of Systems Analysis within the Department of Com- puter Science at the University of Dortmund. He brings together recent results from statistics, epistemology of experimentation, and evolutionary computation. After a long period in which experimentation has been discredited in evo- lutionary computation, it is regaining importance. This book far exceeds a discussion of often-met points of criticism of the usual experimental approach like missing standards, different measures, and inaccurate and irreproducible results. Also, fundamental objections against the experimental approach are discussed and cleared up. This work shows ways and means to close the gap between theoretical and experimental approaches in algorithm engineering. It becomes clear that statistical tests are the beginning and not the end of experimental analyses. Vital in this context is the differentiation between statistically relevant and scientifically meaningful results, which is clearly developed by Thomas Bartz-Beielstein.},
Address = {Berlin, Heidelberg, New York},
Author = {Bartz-Beielstein, Thomas},
Date-Added = {2015-11-29T01:38:42GMT},
Date-Modified = {2017-03-07 21:32:14 +0000},
Doi = {10.1007/3-540-32027-X},
Groups = {bartzPublic},
Isbn = {3-540-32026-1},
Keywords = {bartzPublic, nonfree},
Publisher = {Springer},
Rating = {0},
Series = {Natural Computing Series},
Title = {{Experimental Research in Evolutionary Computation---The New Experimentalism}},
Url = {http://dx.doi.org/10.1007/3-540-32027-X},
Year = {2006},
Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QJi4uLy4uLy4uL3NjaWViby9XZWJzdG9yZS5kL0JhcnQwNmEucGRm0hcLGBlXTlMuZGF0YU8RAUwAAAAAAUwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////wtCYXJ0MDZhLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAMAAwAACiBjdQAAAAAAAAAAAAAAAAAKV2Vic3RvcmUuZAACACsvOlVzZXJzOmJhcnR6OnNjaWVibzpXZWJzdG9yZS5kOkJhcnQwNmEucGRmAAAOABgACwBCAGEAcgB0ADAANgBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvYmFydHovc2NpZWJvL1dlYnN0b3JlLmQvQmFydDA2YS5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AtwC8AMQCFAIWAhsCJgIvAj0CQQJIAlECVgJjAmYCeAJ7AoAAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACgg==},
Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-32027-X}}

@book{bartz2010experimental,
Address = {Germany},
Author = {Chiarandini, Marco and Goegebeur, Yuri},
Booktitle = {Experimental Methods for the Analysis of Optimization Algorithms},
Date-Added = {2015-11-29T01:39:51GMT},
Date-Modified = {2017-10-04 20:17:35 +0000},
Doi = {10.1007/978-3-642-02538-9},
Editor = {Bartz-Beielstein, Thomas and Chiarandini, Marco and Paquete, Luis and Preuss, Mike},
Isbn = {978-3-642-02537-2},
Keywords = {zaef17a},
Pages = {225--264},
Publisher = {Springer},
Rating = {0},
Title = {{Mixed Models for the Analysis of Optimization Algorithms}},
Year = {2010},
}

@incollection{Bart11j,
Abstract = {This chapter comprises the essence of several years of tutorials the authors gave on experimental research in evolutionary computation. We highlight the renaissance of experimental techniques also in other fields to especially focus on the specific conditions of experimental research in com- puter science, or more concrete, metaheuristic optimization. The experimen- tal setup is discussed together with the pitfalls awaiting the unexperienced (and sometimes even the experienced). We present a severity criterion as a meta-statistical concept for evaluating statistical inferences, which can be used to avoid fallacies, i.e., misconceptions resulting from incorrect reasoning in argumentation caused by floor or ceiling effects. The sequential parameter optimization is discussed as a meta-statistical framework which integrates concepts such as severity. Parameter tuning is considered as a relatively new tool in method design and analysis, and it leads to the question of adapt- ability of optimization algorithms. Another branch of experimentation aims for attaining more concrete problem knowledge, we may term it `exploratory landscape analysis', containing sample and visualization techniques that are often applied but not seen as being a methodological contribution. However, this chapter is not only a renarration of well known facts. We also try a look into the future to estimate what the hot topics of methodological research will be in the next years and what changes we may expect for the whole community.},
Address = {Berlin, Heidelberg, New York},
Author = {Bartz-Beielstein, Thomas and Preuss, Mike},
Booktitle = {Theory and Principled Methods for Designing Metaheuristics},
Date-Added = {2015-11-29T01:39:02GMT},
Date-Modified = {2017-03-07 21:20:55 +0000},
Editor = {Borenstein, Yossi and Moraglio, Alberto},
Keywords = {bartzPublic, nonfree},
Pages = {205--245},
Publisher = {Springer},
Rating = {0},
Title = {{Experimental Analysis of Optimization Algorithms: Tuning and Beyond}},
Year = {2014},
Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QJi4uLy4uLy4uL3NjaWViby9XZWJzdG9yZS5kL2JhcnQxMWoucGRm0hcLGBlXTlMuZGF0YU8RAUwAAAAAAUwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////wtiYXJ0MTFqLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAMAAwAACiBjdQAAAAAAAAAAAAAAAAAKV2Vic3RvcmUuZAACACsvOlVzZXJzOmJhcnR6OnNjaWVibzpXZWJzdG9yZS5kOmJhcnQxMWoucGRmAAAOABgACwBiAGEAcgB0ADEAMQBqAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvYmFydHovc2NpZWJvL1dlYnN0b3JlLmQvYmFydDExai5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AtwC8AMQCFAIWAhsCJgIvAj0CQQJIAlECVgJjAmYCeAJ7AoAAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACgg==}}


@article{Bart08a,
Abstract = {
Although theoretical results for several algorithms in many application domains were presented during the last decades, not all algorithms can be analyzed fully theoretically. Experimentation is necessary. The analysis of algorithms should follow the same principles and standards of other empirical sciences. This article focuses on stochastic search algorithms, such as evolutionary algorithms or particle swarm optimization. Stochastic search algorithms tackle hard real-world optimiza- tion problems, e.g., problems from chemical engineering, airfoil optimization, or bio- informatics, where classical methods from mathematical optimization fail. Nowadays statistical tools that are able to cope with problems like small sample sizes, non-normal distributions, noisy results, etc. are developed for the analysis of algorithms. Although there are adequate tools to discuss the statistical significance of experimental data, statistical significance is not scientifically meaningful per se. It is necessary to bridge the gap between the statistical significance of an experimental result and its scientific meaning. We will propose some ideas on how to accomplish this task based on Mayo's learning model (NPTâˆ—).},
Author = {Bartz-Beielstein, Thomas},
Date-Added = {2015-11-29T01:38:36GMT},
Date-Modified = {2017-03-07 21:48:10 +0000},
Doi = {10.1007/s11229-007-9297-z},
Journal = {Synthese},
Keywords = {bartzPublic, nonfree},
Language = {English},
Number = {3},
Pages = {385--396},
Rating = {0},
Title = {{How Experimental Algorithmics Can Benefit from Mayo's Extensions to Neyman-Pearson Theory of Testing}},
Url = {http://link.springer.com/10.1007/s11229-007-9297-z},
Volume = {163},
Year = {2008},
Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QJi4uLy4uLy4uL3NjaWViby9XZWJzdG9yZS5kL2JhcnQwOGEucGRm0hcLGBlXTlMuZGF0YU8RAUwAAAAAAUwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////wtiYXJ0MDhhLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAMAAwAACiBjdQAAAAAAAAAAAAAAAAAKV2Vic3RvcmUuZAACACsvOlVzZXJzOmJhcnR6OnNjaWVibzpXZWJzdG9yZS5kOmJhcnQwOGEucGRmAAAOABgACwBiAGEAcgB0ADAAOABhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvYmFydHovc2NpZWJvL1dlYnN0b3JlLmQvYmFydDA4YS5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AtwC8AMQCFAIWAhsCJgIvAj0CQQJIAlECVgJjAmYCeAJ7AoAAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACgg==},
Bdsk-Url-1 = {http://link.springer.com/10.1007/s11229-007-9297-z},
Bdsk-Url-2 = {http://dx.doi.org/10.1007/s11229-007-9297-z}}
